high concurrency(高并发)

总体架构  spring boot maven jdk8 mysql
mybatis guava lombok redis kafka 

高级组件 ： Joda_Time. Atomic包 JUC AQS ThreadLocal RateLimite
Hystrix threadPool shardbatis curator elastic-job 

first class 
 CPU 多级缓存 ： CPU 执行太快，磁盘读写速度跟不上
 CPU cache 意义： 时间局限性， 空间局限性。
 CPU多级缓存-缓存一致性 ： (MESI)  用于保证多个CPU cache  之间缓存共享数据的一致性
 MESI(modified ,独享， share, invalid )
 四种操作： localread localwrite remote read remote writer
 
 second class 
 
 CPU 多级缓存 -- 乱序执行优化
 （处理器为提高运算速度而做出违背代码原有顺序的优化）
 
 third  java内存模型
 （Java Memory Model, JMM）
 规定一个线程如何和何时能看到其他线程
 
 java 内存模型  同步八种操作与规则
 
 优势与风险
 同时处理多请求。响应更快。
 程序设计在某些情况变得更简单。也有更多选择。
 CPU 能在等待IO时做一些其他的事情。
 多个线程共享数据时可能会产生与期望不符的结果
 死锁 、饥饿等问题。
 线程过多使CPU频繁切换，消耗更多内存。
 
 第三章 ：案例环境搭建
 spring boot 作为基本框架
 git 管理项目代码
 并发模拟：
 1.Apache Bench (AB) 并发模拟：
  ab -n 1000 -c 50 http://localhost:8080/test 
   -n ： 测试请求总数。 -c 本次请求的并发数。
    
2.JMeter 工具
 
典型代码：
 countDownLatch
 ExecutorService
 Semaphore （适合控制同时请求的并发数）
 
 第四章 线程安全性
 概念：不论何种环境，采用何种调度方式，不需要任何额外的同步或协同，这个类都能表现出正确的行为，则成为线程安全。
 
 原子性： 提供互斥访问，同一时刻只能有一个线程来对它进行操作。
 Atomic包 ，主要方法，Unsafe.class  CAS(this.compareAndSwap方法)
 
 AtomicLong 和 LongAdder。
 对于普通类型的Long，double操作，JVM允许将64位操作拆分成32位。
 LongAdder（高并发通过分散降低压力）
 AtomicReference, AtomicReferenceFieldUpdater(原子性更新某一个类的实例，要用volitile修饰，且不能是static的)
 
 AtomicStampReference: CAS的ABA问题
 AtomicBoolean 使用。让某段代码只执行一次
 可见性： 一个线程对对主内存的修改可以及时被其他线程观察到。
 
 
 
 原子性： synchronized 依赖 JVM。(不可中断锁，适合竞争不激烈)
 修饰代码块，同步代码块，作用于调用的对象。
 Lock(可中断锁，多样化同步，竞争激烈能维持常态)
 Atomic 竞争激烈能维持常态，比Lock性能好，但只能同步一个值。
 
 可见性：
 导致共享变量在线程间不可见的原因。
 线程交叉执行。
 
 
 Volatile 通过加入内存屏障和禁止重排序优化来实现。
 对volatile 变量写操作，会在写操作后加入一条store 屏障指令。将本地内存中的共享变量值刷新到主内存。
 对volatile 变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量。
 （适用于： doublecheck， 作为状态标识 ）
 
有序性与总结：
happens -before 原则。
程序次序规则： 一个线程内，按照代码顺序，
锁定规则： unlock操作先于lock.
volatile变量规则： 对一个变量的写操作先行于对这个变量的读操作。

传递规则： 操作A先行发生于操作B. 而操作B又先行发生于操作C,则A操作先行发生于C.
线程启动规则： Thread 对象的Start()方法，先行发生于此线程的每一个动作。
线程中断规则： 对线程interrupt()方法的调用先行发生于被中断线程代码检测到中断事件的发生。
 线程终结规则： 线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束。
 Thread.isAlive()的返回值手段检测到线程已经终止执行。
 
 对象终结规则： 一个对象的初始化完成先行发生于他的finalize()方法的开始。
-------------------------------------------------安全发布对象： 发布与逸出


如何安全的发布对象：
1，静态初始化函数中初始化一个对象引用。
2，将对象的引用保存到volatile类型域或者AtomicReference对象中。
3，将对象的引用保存到某个正确构造对象的final类型域中。
4，将对象的引用保存到一个由锁保护的域中。
------------------------------------
不可变对象： 对象创建后其状态不可修改。
对象所有域都是final类型。
对象是正确创建的（在对象创建期间，this没有发生溢出）

final 关键字。类，方法，变量
修饰类： 不能被继承。
修饰方法： 1.锁定方法不被继承类修改。2效率
修饰变量:基本数据类型变量 （初始化后不能修改）、引用类型变量（初始化后不能指向另一个对象）。

第二种创建不可变对象： Collections.unModifiableXXX: Colleciton\List,Set,Map

Guava: ImmutableXXX Colleciton\List Set map.

----------------------------------------------
线程封闭1：


线程封闭2: 对象封装到一个线程内。
Ad-hoc 线程封闭： 程序控制实现，最糟糕，忽略
堆栈封闭： 局部变量，无并发问题。
ThreadLocal线程封闭： 特别好的封闭方法。利用map实现了线程封闭。

--------------------------------------
线程不安全类与写法

StringBuilder(unsafe) 和StringBuffer  

StringBuffer 使用了synchronized 关键字。对性能可能有影响。

SimpleDateFormat(unsafe)  --> jodaTime


ArrayList , HashSet, HashMap, 等 collections (unsafe)


先检查再执行： (这种写法是线程不安全的。)
if(condition(a)) {handle(a);}

----------------------------------------------
线程安全--同步容器

ArrayList -> Vector,Stack 
HashMap -> HashTable(key,value 不能为null)
Collections.synchronizedXXX(List\Set\Map ) 


---------------------------------------------
线程安全--并发容器 J.U.C
ArrayList  -> CopyOnWriteArrayList
(适用读多写少）（读写分离，最终一致性，使用时另外开辟空间，读不加锁，写加锁）


HashSet. TreeSet-> CopyOnWriteArraySet ,
ConcurrentSkipListSet(使用addAll,removeAll时还是要自己加锁做同步)

HashMap. TreeMap  -> ConcurrentHashMap .ConcurrentSkipListMap 

----------------------------------------
安全共享对象策略总结

线程限制：一个被线程限制的对象，由线程独占，并且只能被占有它的线程修改

共享只读：一个共享只读的对象，在没有额外同步的情况下，可以被多个线程并发访问，但是任何线程都不能修改它。
s
线程安全对象： 一个线程安全的对象或者容器，在内部通过同步机制来保证线程安全，所以其他线程无需额外的同步就可以通过公共接口随意访问它。 

被守护对象： 被守护对象只能通过获取特定的锁来访问

-------------------------------------------
J.U.C 之AQS
AbstractQueuedSyncronizer -AQS 
使用Node 实现FIFO队列，可以用于构建锁或者其他同步装置的基础框架，
利用int类型表示状态， state =0 无线程获得锁 
使用方法---> 继承

子类通过继承并通过实现他的方法管理其状态，{acquire， release} 的方法操纵状态。

可同时实现排他锁，

和共享锁模式（独占、共享）

-----------------------------------------------

AQS 同步组件。CountDownLatch  Semaphore CyclicBarrier ReentrantLock Condition FutureTask



-----------------------------
CountDownLatch: 一个或多个线程需等待其他程序执行完成才能执行。 


---------------------------------
semaphore 控制信号量

=------------------CyclicBarrier 
适用多线程统计结果

多个线程相互等待，才能执行后续操作。


----------------------------------
ReentrantLock与锁

ReentrantLock(可重入锁)与synchronized 区别

可重入性

锁的实现  synchronized(依赖Jvm)


性能区别（synchronized)

功能区别（）

ReentrantLock都有功能，--> 可指定是公平锁还是非公平锁。
提供一个Condition类，可以分组唤醒需要唤醒的线程。

提供能够中断等待锁的线程的机制，lock.lockInerruptibly()
------------------------------------------------
JUC 组件扩展
1.Future/FutureTask
2.Fork/Join 框架
3.BlockingQueue 
ArrayBlockingQueue : 先进先出
DelayQueue: 元素过期时间排序
LinkedBlockingQueue: DelayQueue实例  先进先出插入数据
PriorityBlockingQueue: 允许插入null
SynchronousQueue : 插入一个元素就会阻塞，直至元素被消费。（同步）

________________________________________________


线程池


new Thread 弊端： 每次new Thread 新建对象，性能差。

线程缺乏统一管理，可能无限制的新建线程，相互竞争， 可能占用过多的系统资源导致死机或OOM.

缺少更多功能，如更多执行，定期执行，线程中断

线程池的好处： 
重用存在的线程，减少对象创建，消亡的开销，性能佳。
可有效控制最大并发线程数，提供系统资源利用率，同时可以避免过多资源竞争，避免阻塞。

提供定时执行，定期执行，单线程，并发数控制等功能。

 
 
 ThreadPoolExecutor
 corePoolSize:核心线程数量。
 maximumPoolSize: 线程最大线程数
 workQueue: 阻塞队列，存储等待执行的任务。很重要，会对线程池运行过程产生重大影响。
 keepAliveTime: 线程没有任务执行时最多保持多久时间终止。
 unit: keepAliveTime的时间单位。
 threadFactory: 线程工厂，用来创建线程。
 rejectHandler: 当拒绝处理任务时的策略
---------------------------------------
线程池状态： Running: 处理任务，接受新的任务
shutdown: 不能接受新任务，但能处理
stop：不能处理也不能接受新任务。
Tidying： 如果所有任务终止，所有的线程池为0，调用terminated()进入Teminated状态


execute：提交任务，交给线程池执行。 
submit 提交任务，能够返回执行结果 execute+Future

shutdown: 关闭线程池，等到任务执行完成，
shutdownNow，关闭线程池，不等到任务执行完成。

getTaskCount : 线程池执行和未执行任务的总数。
getCompletedTaskCount(): 已完成的任务数量。
getPoolSize):线程池当前的线程数量。
getActiveCount(): 当前线程池中正在执行任务的线程数量。

线程池 --Executor框架接口

Executors.newCachedThreadPool 创建一个可缓存的线程池

Executors.newFixedThreadPool
创建一个定长的线程池，用于控制并发的数量。
Executors.newScheduledThreadPool，
创建一个定长的线程池，可用于定时执行任务
Executors.newSingleThreadExecutor 
创建一个单线程的线程池，保证只有一个工作线程。

---------------------------------------------
线程池--合理配置

CPU密集型任务，就需要尽量压榨CPU,参考值而已NCPU+1

IO密集型任务，参考值可以设置为2*NCPU.

________________________________________________
高并发处理思路和手段

1。扩容
扩大内存(垂直扩容或纵向扩展)，提高系统部件能力。

增加服务器，（水平扩容或横向扩展）增加更多的系统成员来实现。

数据库：
读操作扩展， memcache, redis, CDN等缓存
写操作扩展， Cassandra ,Hbase等。
——————————————————————————————————————————————
高并发之缓存- 特征，场景及组件介绍

特征： 命中率：命中数/（命中数+没有命中数）
命中率越高，吞吐率越高
最大元素（空间）：缓存清空策略
清空策略：FIFO（First In First Out）, LFU（最少使用策略）,LRU（最近最少使用策略）,过期时间，随机等。

缓存命中率影响因素：
1.业务场景和业务需求： 适用于读多写少的场景。

2. 缓存的设计（粒度和策略）

3.缓存容量和基础设施


缓存分类和应用场景。
1.本地缓存：编程实现，（局部变量，成员变量，静态变量）框架：Guava Cache

2.分布式缓存：Memcache, Redis

________________________________________________
1.Guava Cache 
使用LRU算法移除缓存。

2.Memcache
本身不提供分布式方案。
采用一致性Hash算法。
key最大250字节，

3.redis 
redis核心对象（redisObject）
数据类型（type)
编码方式：encoding,
数据指针
虚拟内存
...

支持持久化，支持数据备份（主从备份）
速度极高 读10W/s  写8w/s
作唯一性检查，构建实时消息系统， 等

-----------------------------------
高并发场景下缓存常见问题

缓存一致性： 
更新数据库成功-更新缓存失败
更新缓存成功-更新数据库失败
更新数据库成功-淘汰缓存失败
淘汰缓存成功-更新数据库失败

缓存并发问题：
 

缓存穿透问题：
1.缓存空对象
2.单独过滤处理

缓存的雪崩现象：
缓存节点故障导致。由于缓存原因导致大量请求到数据库。
过期时间同时失效导致。

============================================
缓存高并发实战---股票分时线

----------------------------------------------
高并发之消息队列思路
特性： 业务无关，制作消息分发。
FIFO: 先投递先到达
容灾： 节点的动态增删和消息的持久化
性能：吞吐量提升，系统内部通信效率提高。

为什么需要消息队列： 【生产】和【消费】的速度或稳定性等因素不一致


消息队列的好处： 
1.业务解耦
2.最终一致性
3.广播
4.错峰与流控


-------------------------------------
应用拆分思路

一个应用拆分成多个。
应用拆分基本原则： 
1. 业务优先
2. 循序渐进
3. 兼顾技术： 重构、分层
4.可靠测试

思考：
应用之间的通信： RPC(dubbo等)、消息队列
应用之间数据库设计： 每个应用都有独立的数据库
避免事务操作跨应用

——————————————————————————————————————————————
 dubbo并不是分布式框架： monitor监控中心。
 Provider 对Consumer是透明的。
 Registry : notify 到 Consumer。
 
 
 微服务：spring cloud
 大型应用拆分为多个微服务。
 分布式服务组成的系统。自动化运维。高度容错性。远程调用。 每个服务提供一个功能。
 
 微服务四个问题： 
 1.客户端如何访问这些服务:
 API Gateway 提供统一的API接口。
 2.服务之间如何通信： 异步通过消息队列。同步通过RPC,或REST
 3.该如何实现这么多服务
 服务感知，服务管理，服务发现，
 Zookeeper + 心跳
 4.服务挂了 怎么解决？
 1重试机制，熔断机制,应用限流。
 
 -----------------------------------------------
应用限流：
算法： 计数器法:一个请求过来count+1，存在一个临界问题。
滑动窗口算法：
漏桶算法：( Leaky Bucket) 接口以恒定速率处理请求
令牌桶算法：Token Bucket) 很好的解决临界问题

计数器算法可看作是滑动窗口的低精度实现
-------------------------------------------------
服务降级与服务熔断

服务降级：
分类： 自动降级（超时，失败次数，故障，限流），人工降级（秒杀，双11大促等）
服务熔断：共性：目的，最终表现，粒度，自治。


他们区别：触发原因，管理目标层次，实现方式

考虑的问题: 


Hystrix: 通过第三方客户端访问（通常是通过网络）依赖服务出现高延迟或者失败时，为系统提供保护和控制机制。

在分布式系统中防止级联失败。

快速失败（Fail fast)同时能快速恢复

提供失败回退（Fallback)和优雅的服务降级机制


------------------------------------------
数据库切库 分库 分表

数据库瓶颈： 单个库数据了过大： 多个库

切库：一个主库 多个从库。 读写分离
查询：主库分离，负载均衡，
自定义注解完成数据库切库---代码实现

支持多数据源和分库的区别: 


分表： 优化SQL和索引已经很难突破性能瓶颈。
横向（水平）分表 和 纵向（垂直）分表
数据库分表： mybatis分表插件shardbatis2.0

------------------------------------------
高可用的一些手段
任务调度系统分布式： elastic-job（当当开源） + zookeeper

主备切换：apache curator + zookeeper 分布式锁实现

（同一时刻只有一台服务器提供服务。主服务器出现问题，备服务器立即提供服务）
（持有锁才能对外提供服务

监控报警机制：
————————————————————————————————————————————
课程总结： 并发编程 和 高并发解决方案







 
 





